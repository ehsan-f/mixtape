% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mix_gcs_read_arrow_dataset-function.R
\name{mix_gcs_read_arrow_dataset}
\alias{mix_gcs_read_arrow_dataset}
\title{Read parquet dataset from Google Cloud Storage using Arrow}
\usage{
mix_gcs_read_arrow_dataset(
  bucket,
  prefix,
  select = NULL,
  select_regex = NULL,
  object_format = "parquet",
  collect = T,
  var_clean_names = F
)
}
\arguments{
\item{bucket}{Name of the Google Cloud Storage bucket}

\item{prefix}{Path to required folder containing parquet files}

\item{select}{Character vector of column names to select (default: NULL for all columns)}

\item{select_regex}{Regular expression to select columns matching pattern (default: NULL)}

\item{object_format}{Format of the file to read ('parquet', 'csv', 'rds') (default: 'parquet')}

\item{collect}{Whether to collect the dataset into memory as a tibble (default: TRUE)}

\item{var_clean_names}{Whether to clean variable names (default: FALSE)}
}
\description{
Reads parquet files from Google Cloud Storage as a unified dataset using arrow's open_dataset functionality.
This is more efficient than reading files one by one as it allows lazy evaluation and partitioned reading.
}
