% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mix_ml_tunez-function.R
\name{mix_ml_tunez}
\alias{mix_ml_tunez}
\title{Tune XGBoost model hyperparameters using cross-validation}
\usage{
mix_ml_tunez(
  training_data,
  recipe,
  n_folds = 3,
  n_workers = NULL,
  learn_rate_values = c(0.01),
  min_n_values = c(0.003, 0.005),
  alpha_values = c(5, 8, 10),
  lambda_values = c(5, 10, 15),
  trees_values = c(1500, 2000),
  tree_depth_values = c(8, 10, 12),
  sample_size_values = c(0.75),
  colsample_bytree_values = c(0.75),
  early_stopping_rounds = 20,
  seed = 123,
  parallel_type = "everything"
)
}
\arguments{
\item{training_data}{Training dataset}

\item{recipe}{A tidymodels recipe object defining preprocessing steps}

\item{n_folds}{Number of cross-validation folds (default: 3)}

\item{n_workers}{Number of parallel workers (optional, auto-calculated if NULL)}

\item{learn_rate_values}{Learning rate values to test (default: c(0.01))}

\item{min_n_values}{Minimum node size values as proportion of training rows (default: c(0.003, 0.005))}

\item{alpha_values}{L1 regularization values to test (default: c(5, 8, 10))}

\item{lambda_values}{L2 regularization values to test (default: c(5, 10, 15))}

\item{trees_values}{Number of trees values to test (default: c(1500, 2000))}

\item{tree_depth_values}{Maximum tree depth values to test (default: c(8, 10, 12))}

\item{sample_size_values}{Row sampling proportion values to test (default: c(0.75))}

\item{colsample_bytree_values}{Column sampling proportion values to test (default: c(0.75))}

\item{early_stopping_rounds}{Number of rounds without improvement before stopping (default: 20)}

\item{seed}{Random seed for reproducibility (default: 123)}

\item{parallel_type}{Parallelization strategy: 'everything' or 'resamples' (default: 'everything')}
}
\value{
A list containing:
\describe{
\item{cv_models}{Slimmed workflow objects for best hyperparameters (one per fold) for ensemble predictions}
\item{best_params}{Best hyperparameter combination based on ROC AUC}
\item{tune_results}{Top 20 hyperparameter combinations with performance metrics}
\item{training_time}{Total time taken for hyperparameter tuning}
}
}
\description{
Performs hyperparameter tuning for XGBoost classification models using k-fold
cross-validation with parallel processing. Returns the best hyperparameters and
lightweight CV models for ensemble predictions. Models are automatically slimmed
using the butcher package to reduce memory footprint.
}
